# Slide 1: Title Slide
**MoodBoard ðŸŽ­**  
*An Emotion-Driven Visual Playground*

- Final Project for SI379
- Created by Zichen Zang

---

# Slide 2: Live Demo
**Project in Action**

ðŸŽ¥ Short screen recording showing:
- Webcam activation
- Mood changes when smiling / neutral
- Emoji animations responding to emotion
- Speed slider and emoji theme switcher

ðŸ“Œ Link to project (GitHub Pages/Vercel)

**Speaker Notes:**
- â€œThis is how MoodBoard works. It uses your webcam to detect your facial expression and animates the page with emojis and colors that reflect your mood.â€
- â€œYou can also use the controls to change the speed and emoji style.â€

---

# Slide 3: Tech Stack Overview
**What Powers MoodBoard**

- âœ… React.js for app structure and state
- âœ… p5.js for canvas drawing and animation
- âœ… ml5.js (FaceMesh) for emotion detection
- âœ… HTML/CSS for UI controls and layout

**Speaker Notes:**
- â€œI combined creative coding with front-end development to make a project thatâ€™s fun and expressive.â€
- â€œLetâ€™s look at how each library was used.â€

---

# Slide 4: React.js â€“ App Structure

**What React Does**
- Manages emotion state with `useState`
- Mounts canvas using `useRef`
- Controls setup with `useEffect`

**Speaker Notes:**
- â€œReact helped keep everything modular and responsive. The canvas is mounted using `useRef`, and the speed and theme are stored as state.â€

---

# Slide 5: p5.js â€“ Visuals & Animation

**What p5 Does**
- Draws emojis and background
- Displays webcam on canvas
- Handles window resizing

```js
p.draw = () => {
  p.text("ðŸ’–", x, y);
}
```

**Speaker Notes:**
- â€œp5 handles the visuals â€” emojis float around depending on your mood. It also draws the webcam feed and emotion label.â€

---

# Slide 6: ml5.js + FaceMesh â€“ Emotion Detection

**Real-time ML with no training required**

```js
faceMesh.detectStart(video.elt, results => {
  const lips = results[0].lips;
  const ratio = lips.width / lips.height;
  setEmotion(ratio > 2.5 || ratio < 1.6 ? "happy" : "sad");
});
```

**Speaker Notes:**
- â€œThis is the heart of the emotion detection. It uses FaceMesh to track your mouth width and height â€” no server or AI training needed.â€

---

# Slide 7: UI Controls â€“ Sliders + Selectors

- ðŸŽ› Slider to adjust speed
- ðŸŽ¨ Dropdown to switch emoji style
- ðŸ“ Styled with inline CSS + absolute layout

**Speaker Notes:**
- â€œThis lets users customize the animation feel. You can go calm or intense, and switch between fun emoji themes.â€

---

# Slide 8: Why This Project?

- I wanted to build something emotionally expressive
- Combines my interests in design, emotion, and playful tech
- Works entirely in-browser, accessible to anyone

**Speaker Notes:**
- â€œI love exploring how emotion can be visualized interactively. MoodBoard is a fun way to do that.â€

---

# Slide 9: Try It Yourself!

- ðŸŒ GitHub Pages / Vercel link to run live
- ðŸ’» Source code on GitHub
- ðŸ“ README with setup instructions

**Speaker Notes:**
- â€œYou can try it right now from your browser â€” and the code is open if you want to remix it!â€

---

# Slide 10: Thank You!
**Questions? Feedback? Mood suggestions?**  
ðŸ˜„ ðŸ˜¢ ðŸŒˆ ðŸ’§

- Zichen Zang, SI379 Final Project
